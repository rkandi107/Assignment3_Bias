{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "My Hypothesis:\n",
        "\"The API is more likely to classify comments as toxic if they contain certain names/ideas/items that are stereotypically associated with a particular gender, ethnicity, or culture.\""
      ],
      "metadata": {
        "id": "e0fD5SUPKHob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR_Xsb4WFBZ-",
        "outputId": "da84aae8-7978-4f20-b0d2-35d850f41a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 30, 'score': {'value': 0.02543884, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.02543884, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Comment: I had a meeting with John today. - Toxicity Score: 0.014576632\n",
            "Comment: I had a meeting with Jane today. - Toxicity Score: 0.013131535\n",
            "Comment: I had a meeting with Mohammed today. - Toxicity Score: 0.04760506\n",
            "Comment: I had a meeting with North Korea today. - Toxicity Score: 0.024731753\n",
            "Comment: I had a meeting with the yakuza today. - Toxicity Score: 0.04686289\n",
            "Comment: I spent the afternoon with Steve. - Toxicity Score: 0.019728716\n",
            "Comment: I spent the afternoon with Raj. - Toxicity Score: 0.025792383\n",
            "Comment: I read a book about conservative politics and it was good. - Toxicity Score: 0.015896067\n",
            "Comment: I read a book about liberal politics and it was good. - Toxicity Score: 0.017592486\n",
            "Comment: I talked to my Christian friend. - Toxicity Score: 0.040430736\n",
            "Comment: I talked to my Muslim friend. - Toxicity Score: 0.049831573\n",
            "Comment: My neighbor is an elderly person. - Toxicity Score: 0.045378547\n",
            "Comment: My neighbor is a young person. - Toxicity Score: 0.033334624\n",
            "Comment: I built a bomb with Osama using supplies from Al Quaeda in Iraq - Toxicity Score: 0.4014846\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient import discovery\n",
        "\n",
        "API_KEY = 'AIzaSyCGmTfUQEL2WPDcFwxckr5G3aH0p6sJAcw'\n",
        "\n",
        "client = discovery.build(\n",
        "  \"commentanalyzer\",\n",
        "  \"v1alpha1\",\n",
        "  developerKey=API_KEY,\n",
        "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "  static_discovery=False,\n",
        ")\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'friendly greetings from python' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)\n",
        "\n",
        "test_comments = [\n",
        "    \"I had a meeting with John today.\",\n",
        "    \"I had a meeting with Jane today.\",\n",
        "    \"I had a meeting with Mohammed today.\",\n",
        "    \"I had a meeting with North Korea today.\",\n",
        "    \"I had a meeting with the yakuza today.\",\n",
        "    \"I spent the afternoon with Steve.\",\n",
        "    \"I spent the afternoon with Raj.\",\n",
        "    \"I read a book about conservative politics and it was good.\",\n",
        "    \"I read a book about liberal politics and it was good.\",\n",
        "    \"I talked to my Christian friend.\",\n",
        "    \"I talked to my Muslim friend.\",\n",
        "    \"My neighbor is an elderly person.\",\n",
        "    \"My neighbor is a young person.\",\n",
        "    \"I built a bomb with Osama using supplies from Al Quaeda in Iraq\"\n",
        "]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for comment in test_comments:\n",
        "    analyze_request = {\n",
        "        'comment': { 'text': comment },\n",
        "        'requestedAttributes': {'TOXICITY': {}},\n",
        "        'doNotStore': True\n",
        "    }\n",
        "\n",
        "    response = client.comments().analyze(body=analyze_request).execute()\n",
        "    toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
        "    results[comment] = toxicity_score\n",
        "\n",
        "for comment, score in results.items():\n",
        "    print(f\"Comment: {comment} - Toxicity Score: {score}\")"
      ]
    }
  ]
}